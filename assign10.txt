import pandas as pd

# Your DataFrame
data = {
    'Name': ['John', 'Emily', 'Michael', 'Jessica'],
    'Age': [25, 28, 32, 30],
    'City': ['New York', 'Los Angeles', 'Chicago', 'Houston'],
    'Salary': [50000, 60000, 70000, 55000]
}
df = pd.DataFrame(data)

# 1. Introducing Pandas Objects:
# a) Print the entire DataFrame `df`
print(df)

# b) Determine and print the shape of the DataFrame `df`
print(df.shape)

# c) Identify the data types of each column in the DataFrame `df`
print(df.dtypes)

# 2. Data Indexing and Selection:
# a) Access and print the 'Name' column of the DataFrame `df`
print(df['Name'])

# b) Access and print the second row of the DataFrame `df`
print(df.iloc[1])

# c) Access and print the salary of the employee with the name 'Michael'
print(df.loc[df['Name'] == 'Michael', 'Salary'])

# d) Create a new DataFrame `df_filtered` that includes only the rows where the age is greater than 27
df_filtered = df[df['Age'] > 27]
print(df_filtered)





import numpy as np
import pandas as pd

# Define the DataFrame
data = {
    'Name': ['John', 'Emily', 'Michael', 'Jessica'],
    'Age': [25, 28, 32, 30],
    'City': ['New York', 'Los Angeles', 'Chicago', 'Houston'],
    'Salary': [50000, 60000, 70000, 55000]
}
df = pd.DataFrame(data)
# Part 1: Operating on Data in Pandas
# a) Calculate the mean age
mean_age = df['Age'].mean()
# b) Calculate the total salary of all employees
total_salary = df['Salary'].sum()
# c) Calculate the maximum salary among all employees
max_salary = df['Salary'].max()
# Part 2: Data Manipulation
# a) Add a new column 'Bonus' with random values between 1000 and 5000 for each employee
np.random.seed(42)  # Setting seed for reproducibility
df['Bonus'] = np.random.randint(1000, 5000, size=len(df))
# b) Increase the salary of all employees by 10%
df['Salary'] *= 1.10  # Applying a 10% increase
# Part 3: Data Aggregation
# a) Group by 'City' and calculate the average age for each city
grouped_avg_age = df.groupby('City')['Age'].mean().reset_index()
# b) Group by 'City' and calculate the total salary for each city
grouped_total_salary = df.groupby('City')['Salary'].sum().reset_index()
# Print results
print("Mean Age:", mean_age)  # Mean age
print("Total Salary:", total_salary)  # Total salary
print("Maximum Salary:", max_salary)  # Maximum salary
print("\nDataFrame with Bonus Column:")
print(df.to_string(index=False))  # DataFrame with bonus column
print("\nAverage Age by City:")
print(grouped_avg_age.to_string(index=False))  # Average age by city
print("\nTotal Salary by City:")
print(grouped_total_salary.to_string(index=False))  # Total salary by city




import pandas as pd
import numpy as np

# Define the DataFrame with some missing data
data = {
    'Name': ['John', 'Emily', np.nan, 'Jessica'],
    'Age': [25, np.nan, 32, 30],
    'City': ['New York', 'Los Angeles', 'Chicago', np.nan],
    'Salary': [50000, 60000, np.nan, 55000]
}
df = pd.DataFrame(data)

# Part 1: Detection of Missing Data
# a) Identify and print the total number of missing values in each column
total_missing = df.isnull().sum()  # Total missing values in each column

# b) Determine and print the percentage of missing values in the 'Age' column
age_missing_percentage = df['Age'].isnull().mean() * 100  # Percentage of missing values in the 'Age' column

print("Total Missing Values in Each Column:")
print(total_missing)

print("\nPercentage of Missing Values in 'Age' Column:")
print(f"{age_missing_percentage:.2f}%")

# Part 2: Handling of Missing Data
# a) Remove rows that contain missing values and assign the result to a new DataFrame `df_clean`
df_clean = df.dropna()  # Remove rows with any missing values

# b) Fill the missing values in the 'Salary' column with the mean salary value
mean_salary = df['Salary'].mean()  # Calculate mean salary
df_filled = df.copy()  # Create a copy of the original DataFrame
df_filled['Salary'] = df_filled['Salary'].fillna(mean_salary)  # Fill missing salary with mean salary

print("\nDataFrame After Removing Rows with Missing Values:")
print(df_clean.to_string(index=False))

print("\nDataFrame After Filling Missing Salary with Mean:")
print(df_filled.to_string(index=False))




import pandas as pd
import numpy as np

# Create the DataFrame with missing values
data = {
    'Name': ['John', 'Emily', np.nan, 'Jessica'],
    'Age': [25, np.nan, 32, 30],
    'City': ['New York', 'Los Angeles', 'Chicago', np.nan],
    'Salary': [50000, 60000, np.nan, 55000]
}
df = pd.DataFrame(data)

# Part 1: Detection of Missing Data
# a) Identify the total number of missing values in each column
missing_values_per_column = df.isna().sum()

# b) Determine the percentage of missing values in the 'Age' column
total_rows = len(df)
age_missing_percentage = (missing_values_per_column['Age'] / total_rows) * 100

# Part 2: Handling of Missing Data
# a) Remove rows with missing values and assign to a new DataFrame df_clean
df_clean = df.dropna()

# b) Fill the missing values in the 'Salary' column with the mean salary value
mean_salary = df['Salary'].mean()  # Calculate the mean salary
df_filled = df.copy()  # Create a copy to avoid altering the original DataFrame
df_filled['Salary'] = df_filled['Salary'].fillna(mean_salary)  # Fill the missing salary with the mean

# Print results
print("Total number of missing values in each column:\n", missing_values_per_column)
print("\nPercentage of missing values in the 'Age' column:", age_missing_percentage, "%")
print("\nDataFrame after removing rows with any missing values (df_clean):\n", df_clean)
print("\nDataFrame after filling missing values in the 'Salary' column with the mean salary (df_filled):\n", df_filled)





import pandas as pd

# Create the DataFrame with a MultiIndex
data = {
    'Group': ['A', 'A', 'B', 'B', 'C', 'C'],
    'Category': ['X', 'Y', 'X', 'Y', 'X', 'Y'],
    'Value': [10, 20, 30, 40, 50, 60]
}
df = pd.DataFrame(data)

# Set a hierarchical index with 'Group' and 'Category'
df = df.set_index(['Group', 'Category'])

# Part 1: Hierarchical Indexing
# a) Print the DataFrame with hierarchical index
print("DataFrame with Hierarchical Index:")
print(df)

# b) Access and print the value corresponding to Group 'A' and Category 'X'
value_a_x = df.loc[('A', 'X'), 'Value']
print("\nValue for Group 'A' and Category 'X':", value_a_x)

# c) Access and print the sub-dataframe corresponding to all rows with Group 'B'
sub_df_b = df.loc['B']  # Retrieve the sub-dataframe for Group 'B'
print("\nSub-dataframe for Group 'B':")
print(sub_df_b)




import pandas as pd
import numpy as np
import matplotlib.pyplot as plt

# Data for the operations
data = {
    'Year': [2015, 2016, 2017, 2018, 2019, 2020],
    'Sales': [100, 150, 200, 180, 220, 250],
    'Profit': [10, 20, 25, 15, 30, 35]
}
df = pd.DataFrame(data)

# Part 1: Visualization with Matplotlib
# a) Line plot to visualize the trend of sales over the years
plt.figure(figsize=(8, 6))
plt.plot(df['Year'], df['Sales'], marker='o', linestyle='-', color='b', label='Sales')
plt.xlabel("Year")
plt.ylabel("Sales")
plt.title("Trend of Sales over the Years")
plt.grid(True)
plt.legend()
plt.show()

# b) Bar plot to compare the sales and profit for each year
plt.figure(figsize=(10, 6))
bar_width = 0.4
index = np.arange(len(df['Year']))
plt.bar(index, df['Sales'], bar_width, color='b', label='Sales')
plt.bar(index + bar_width, df['Profit'], bar_width, color='g', label='Profit')
plt.xlabel("Year")
plt.ylabel("Value")
plt.title("Sales and Profit Comparison by Year")
plt.xticks(index + bar_width / 2, df['Year'])
plt.legend()
plt.show()

# c) Scatter plot to show the relationship between sales and profit
plt.figure(figsize=(8, 6))
plt.scatter(df['Sales'], df['Profit'], color='r', label='Sales vs Profit')
plt.xlabel("Sales")
plt.ylabel("Profit")
plt.title("Scatter Plot of Sales vs Profit")
plt.grid(True)
plt.show()

# d) Box plot to display the distribution of sales and profit
plt.figure(figsize=(8, 6))
plt.boxplot([df['Sales'], df['Profit']], labels=['Sales', 'Profit'])
plt.xlabel("Category")
plt.ylabel("Value")
plt.title("Box Plot of Sales and Profit")
plt.show()

# e) Histogram to visualize the distribution of sales
plt.figure(figsize=(8, 6))
plt.hist(df['Sales'], bins=5, color='b', alpha=0.7)
plt.xlabel("Sales")
plt.ylabel("Frequency")
plt.title("Histogram of Sales")
plt.show()

# f) Pie chart to represent the proportion of sales for each year
plt.figure(figsize=(8, 8))
plt.pie(df['Sales'], labels=df['Year'], autopct='%1.1f%%', startangle=90, colors=plt.cm.tab20.colors)
plt.title("Pie Chart of Sales by Year")
plt.show()  # Displaying all plots





import pandas as pd

# Define the Series
series = pd.Series(['apple', 'banana', 'cherry', 'durian', 'elderberry'])

# Part 1: Vectorized String Operations
# a) Convert all strings to uppercase
upper_series = series.str.upper()
print("Uppercase Series:")
print(upper_series)

# b) Determine the length of each string
string_lengths = series.str.len()
print("\nLength of each string:")
print(string_lengths)

# c) Check if each string contains the letter 'a'
contains_a = series.str.contains('a')
print("\nContains 'a':")
print(contains_a)

# d) Replace all occurrences of the letter 'a' with 'x'
replace_a_with_x = series.str.replace('a', 'x')
print("\nReplace 'a' with 'x':")
print(replace_a_with_x)

# e) Extract the first three characters from each string
first_three_characters = series.str[:3]
print("\nFirst three characters:")
print(first_three_characters)

# f) Count the occurrences of the letter 'r' in each string
count_r = series.str.count('r')
print("\nCount of 'r' in each string:")
print(count_r)
